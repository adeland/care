import pandas as pd
import numpy as np
import tensorflow as tf
from transformers import BertTokenizer, TFBertModel
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.metrics import BinaryAccuracy
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Dense, Input
from google.colab import drive

drive.mount("/content/drive", force_remount = True)

file_path = '/content/drive/My Drive/data.csv'
data = pd.read_csv(file_path)

texts = data['Answer'].values
labels = data.iloc[:, 1:].astype(int).values

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

input_ids = []
attention_masks = []

for text in texts:
    encoded_dict = tokenizer.encode_plus(
        text,
        add_special_tokens = True,
        max_length = 64,
        padding = "max_length",
        return_attention_mask = True,
        return_tensors = "tf",
        truncation = True,
    )
    input_ids.append(encoded_dict['input_ids'])
    attention_masks.append(encoded_dict['attention_mask'])

input_ids = tf.concat(input_ids, axis = 0)
attention_masks = tf.concat(attention_masks, axis = 0)

input_ids_np = input_ids.numpy() if not isinstance(input_ids, np.ndarray) else input_ids
attention_masks_np = attention_masks.numpy() if not isinstance(attention_masks, np.ndarray) else attention_masks

train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(
    input_ids_np, labels, random_state = 2018, test_size = 0.1)

train_masks, validation_masks, _, _ = train_test_split(
    attention_masks_np, np.zeros(attention_masks_np.shape[0]), random_state = 2018, test_size = 0.1)

bert_model = TFBertModel.from_pretrained('bert-base-uncased')

input_id_layer = Input(shape = (64,), dtype ='int32')
input_mask_layer = Input(shape=(64,), dtype ='int32')
embeddings = bert_model(input_id_layer, attention_mask = input_mask_layer).pooler_output
out = Dense(units=labels.shape[1], activation = 'sigmoid')(embeddings)

model = tf.keras.Model(inputs = [input_id_layer, input_mask_layer], outputs = out)

model.compile(optimizer = Adam(learning_rate = 2e-5),
              loss = BinaryCrossentropy(),
              metrics = [BinaryAccuracy(name = 'accuracy')])

history = model.fit(
    [train_inputs, train_masks],
    train_labels,
    batch_size = 32,
    epochs = 4,
    validation_data = ([validation_inputs, validation_masks], validation_labels),
    callbacks = [EarlyStopping(patience = 2, restore_best_weights = True)]
)
